{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация тональности коротких текстов [SpaCy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from spacy.tokens import DocBin\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.data/women_clothing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nikgo\\Documents\\NSU\\NLP\\NLP_labs\\lab_02\\lab2.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikgo/Documents/NSU/NLP/NLP_labs/lab_02/lab2.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Загрузить датасет\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nikgo/Documents/NSU/NLP/NLP_labs/lab_02/lab2.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m.data/women_clothing.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf8\u001b[39;49m\u001b[39m'\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikgo/Documents/NSU/NLP/NLP_labs/lab_02/lab2.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df\n",
      "File \u001b[1;32mc:\\Users\\nikgo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\nikgo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\nikgo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\nikgo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\nikgo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.data/women_clothing.csv'"
     ]
    }
   ],
   "source": [
    "# Загрузить датасет\n",
    "df = pd.read_csv('data/women_clothing.csv', encoding='utf8', sep='\\t')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убрать класс neutral\n",
    "df = df[df['sentiment'] != 'neautral']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделить данные на обучающий и валидационный наборы\n",
    "train_data, valid_data = train_test_split(df, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list(tuple(text, label)) -> List(spacy.Doc.doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.6.0/ru_core_news_sm-3.6.0-py3-none-any.whl (15.3 MB)\n",
      "     ---------------------------------------- 0.0/15.3 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/15.3 MB 660.6 kB/s eta 0:00:24\n",
      "     --------------------------------------- 0.0/15.3 MB 393.8 kB/s eta 0:00:39\n",
      "     --------------------------------------- 0.1/15.3 MB 819.2 kB/s eta 0:00:19\n",
      "      --------------------------------------- 0.2/15.3 MB 1.1 MB/s eta 0:00:15\n",
      "      --------------------------------------- 0.3/15.3 MB 1.1 MB/s eta 0:00:14\n",
      "      --------------------------------------- 0.4/15.3 MB 1.4 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.4/15.3 MB 1.3 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.6/15.3 MB 1.7 MB/s eta 0:00:09\n",
      "     -- ------------------------------------- 0.9/15.3 MB 2.2 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 1.2/15.3 MB 2.8 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.2/15.3 MB 2.8 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.6/15.3 MB 2.9 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.7/15.3 MB 3.1 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.7/15.3 MB 3.1 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.7/15.3 MB 3.1 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 2.3/15.3 MB 3.1 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.9/15.3 MB 3.7 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.9/15.3 MB 3.6 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 3.1/15.3 MB 3.6 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 3.1/15.3 MB 3.6 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 3.7/15.3 MB 3.8 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 4.5/15.3 MB 4.4 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 4.5/15.3 MB 4.4 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 4.7/15.3 MB 4.2 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 4.8/15.3 MB 4.2 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 5.0/15.3 MB 4.2 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 5.1/15.3 MB 4.0 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 5.3/15.3 MB 4.1 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 5.4/15.3 MB 4.0 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 5.7/15.3 MB 4.1 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 5.9/15.3 MB 4.1 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 6.2/15.3 MB 4.1 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 6.5/15.3 MB 4.2 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 6.7/15.3 MB 4.2 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 6.9/15.3 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 7.2/15.3 MB 4.3 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 7.4/15.3 MB 4.3 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 7.7/15.3 MB 4.4 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 8.0/15.3 MB 4.4 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 8.2/15.3 MB 4.4 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 8.5/15.3 MB 4.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 8.7/15.3 MB 4.5 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 9.0/15.3 MB 4.5 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 9.3/15.3 MB 4.6 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 9.5/15.3 MB 4.6 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 9.8/15.3 MB 4.6 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 10.1/15.3 MB 4.6 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 10.3/15.3 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 10.6/15.3 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 10.9/15.3 MB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 11.2/15.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 11.4/15.3 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 11.7/15.3 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 11.9/15.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 12.2/15.3 MB 5.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 12.5/15.3 MB 5.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 12.7/15.3 MB 5.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 12.9/15.3 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 13.2/15.3 MB 5.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 13.5/15.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 13.8/15.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 14.0/15.3 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.3/15.3 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 14.6/15.3 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 14.9/15.3 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.2/15.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.2/15.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 15.3/15.3 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in d:\\develop\\python310\\lib\\site-packages (from ru-core-news-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in d:\\develop\\python310\\lib\\site-packages (from ru-core-news-sm==3.6.0) (1.2.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in d:\\develop\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.6.0) (0.7.2)\n",
      "Requirement already satisfied: docopt-ng>=0.6 in d:\\develop\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in d:\\develop\\python310\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.6.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (1.25.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\develop\\python310\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\develop\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in d:\\develop\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\develop\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\develop\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\develop\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\develop\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\develop\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in d:\\develop\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\develop\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in d:\\develop\\python310\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\develop\\python310\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\develop\\python310\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->ru-core-news-sm==3.6.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_sm\") # небольшой на русском"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_docs(data):\n",
    "    \"\"\"\n",
    "    this will take a list of texts and labels\n",
    "    and transform them in spacy documents\n",
    "    data: list(tuple(text, label))\n",
    "    returns: List(spacy.Doc.doc)\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    # nlp.pipe([texts]) is way faster than running\n",
    "    # nlp(text) for each text\n",
    "    # as_tuples allows us to pass in a tuple,\n",
    "    # the first one is treated as text\n",
    "    # the second one will get returned as it is.\n",
    "    for doc, label in tqdm(nlp.pipe(data, as_tuples=True), total = len(data)):\n",
    "        # One Hot Encodding\n",
    "        if label == 'negative':\n",
    "            doc.cats[\"positive\"] = 0\n",
    "            doc.cats[\"negative\"] = 1\n",
    "        else:\n",
    "            doc.cats[\"positive\"] = 1\n",
    "            doc.cats[\"negative\"] = 0\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d4c276496f4fea8292330181bb033b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_docs = make_docs(train_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a25632f51254175a976150e5c64f6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_docs = make_docs(valid_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись на диск\n",
    "doc_bin = DocBin(docs=train_docs)\n",
    "doc_bin.to_disk(\"train.spacy\")\n",
    "\n",
    "doc_bin = DocBin(docs=valid_docs)\n",
    "doc_bin.to_disk(\"valid.spacy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spacy.io/usage/training#quickstart\n",
    "\n",
    "base_config:\n",
    "\n",
    "[paths]<br />\n",
    "train = train.spacy<br />\n",
    "dev = valid.spacy<br />\n",
    "vectors = null<br />\n",
    "[system]<br />\n",
    "gpu_allocator = null<br />\n",
    "\n",
    "[nlp]<br />\n",
    "lang = \"ru\"<br />\n",
    "pipeline = [\"textcat\"]<br />\n",
    "batch_size = 1000<br />\n",
    "\n",
    "[components]<br />\n",
    "\n",
    "[components.textcat]<br />\n",
    "factory = \"textcat\"<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# на основе base_config сделать config.cfg\n",
    "! python -m spacy init fill-config base_config.cfg config.cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config:\n",
    "\n",
    "[training]<br />\n",
    "dev_corpus = \"corpora.dev\"<br />\n",
    "train_corpus = \"corpora.train\"<br />\n",
    "seed = ${system.seed}<br />\n",
    "gpu_allocator = \\${system.gpu_allocator}<br />\n",
    "dropout = 0.1<br />\n",
    "accumulate_gradient = 1<br />\n",
    "patience = 1600<br />\n",
    "max_epochs = 2<br />\n",
    "max_steps = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: \\content\\output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.005\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.25       60.50    0.60\n",
      "  0     100         14.52       83.79    0.84\n",
      "  0     200         13.49       85.10    0.85\n",
      "  0     300         11.78       87.68    0.88\n",
      "  0     400          9.87       88.74    0.89\n",
      "  0     500          8.93       89.57    0.90\n",
      "  0     600          7.68       90.00    0.90\n",
      "  0     700          5.93       90.48    0.90\n",
      "  0     800          6.51       90.58    0.91\n",
      "  0     900          6.77       90.73    0.91\n",
      "  0    1000          7.29       91.00    0.91\n",
      "  0    1100          7.36       91.28    0.91\n",
      "  0    1200          6.96       91.31    0.91\n",
      "  0    1300          7.07       91.65    0.92\n",
      "  0    1400          5.82       91.73    0.92\n",
      "  0    1500          6.14       91.80    0.92\n",
      "  0    1600          6.54       91.99    0.92\n",
      "  0    1700          5.93       92.13    0.92\n",
      "  0    1800          5.81       92.38    0.92\n",
      "  0    1900          6.01       92.29    0.92\n",
      "  0    2000          6.57       92.43    0.92\n",
      "  0    2100          6.02       92.48    0.92\n",
      "  0    2200          6.01       92.60    0.93\n",
      "  0    2300          5.94       92.62    0.93\n",
      "  0    2400          6.24       92.40    0.92\n",
      "  0    2500          5.91       92.75    0.93\n",
      "  1    2600          5.24       92.78    0.93\n",
      "  1    2700          3.79       92.91    0.93\n",
      "  1    2800          3.01       92.80    0.93\n",
      "  1    2900          3.41       92.75    0.93\n",
      "  1    3000          3.96       92.72    0.93\n",
      "  1    3100          3.41       92.61    0.93\n",
      "  1    3200          3.55       92.75    0.93\n",
      "  1    3300          4.29       92.78    0.93\n",
      "  1    3400          3.43       92.86    0.93\n",
      "  1    3500          3.70       92.68    0.93\n",
      "  1    3600          3.22       92.79    0.93\n",
      "  1    3700          3.75       92.79    0.93\n",
      "  2    3800          2.68       92.74    0.93\n",
      "  2    3900          2.55       92.71    0.93\n",
      "  2    4000          2.82       92.68    0.93\n",
      "  2    4100          2.53       92.73    0.93\n",
      "  2    4200          2.78       92.69    0.93\n",
      "  2    4300          2.94       92.75    0.93\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "\\content\\output\\model-last\n",
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.25       60.50    0.60\n",
      "  0     200         36.14       85.63    0.86\n",
      "  0     400         25.35       87.60    0.88\n",
      "  0     600         19.35       89.21    0.89\n",
      "  0     800         16.42       89.80    0.90\n",
      "  0    1000         16.28       90.62    0.91\n",
      "  0    1200         15.97       91.05    0.91\n",
      "  0    1400         14.30       91.51    0.92\n",
      "  0    1600         13.98       91.86    0.92\n",
      "  0    1800         12.89       92.08    0.92\n",
      "  0    2000         13.23       92.33    0.92\n",
      "  0    2200         12.37       92.57    0.93\n",
      "  0    2400         12.54       92.62    0.93\n",
      "  1    2600         11.80       92.78    0.93\n",
      "  1    2800          9.28       92.89    0.93\n",
      "  1    3000          9.40       92.82    0.93\n",
      "  1    3200          8.83       92.99    0.93\n",
      "  1    3400          9.60       93.09    0.93\n",
      "  1    3600          8.74       92.97    0.93\n",
      "  2    3800          8.44       93.13    0.93\n",
      "  2    4000          7.87       93.02    0.93\n",
      "  2    4200          7.53       92.98    0.93\n",
      "  2    4400          8.30       93.25    0.93\n",
      "  2    4600          7.69       93.12    0.93\n",
      "  2    4800          7.11       93.27    0.93\n",
      "  3    5000          7.12       93.14    0.93\n",
      "  3    5200          6.58       93.15    0.93\n",
      "  3    5400          6.28       93.19    0.93\n",
      "  3    5600          6.36       93.22    0.93\n",
      "  3    5800          6.89       93.19    0.93\n",
      "  4    6000          7.06       93.33    0.93\n",
      "  4    6200          5.63       93.24    0.93\n",
      "  4    6400          5.77       93.16    0.93\n",
      "  4    6600          5.86       93.11    0.93\n",
      "  4    6800          6.10       93.24    0.93\n",
      "  4    7000          6.23       93.17    0.93\n",
      "  5    7200          6.04       93.32    0.93\n",
      "  5    7400          5.20       93.17    0.93\n",
      "  5    7600          5.13       93.16    0.93\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output\\model-last\n"
     ]
    }
   ],
   "source": [
    "# тренируем модель\n",
    "! python -m spacy train config.cfg --output ./output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type : ‘quit’ to exit\n",
      "Заказывала фиолетовую кофту размер XL, пришла очень маленькая кофта по длине 53 см и по груди тоже-детская разм. меньше чем S. Очень расстроилась, по спору присудили возврат денег 27 декабря. Выплата от 3 до 20 дней. Прошло уже 24 дня, деньги продавец не вернул, на сообщения не отвечает! Кофту такого смешного размера носить нельзя. Продавец непорядочный! Непонятно, почему Алиэкспресс после спора не отслеживают возвраты денег!\n",
      "{'positive': 2.409719090934459e-09, 'negative': 1.0}\n",
      "the sentiment is negative\n",
      "Ужасная синтетика! Тонкая, ничего общего с представленной картинкой, не яркая, рисунок растянут и тусклый, впрочем как и сама кофта- мешок! На картинке кажется приталенной на самом деле нет! Не рекомендую\n",
      "{'positive': 5.0845348596340045e-05, 'negative': 0.9999490976333618}\n",
      "the sentiment is negative\n",
      "Немного маловато,но жене понравилось\n",
      "{'positive': 0.9905748963356018, 'negative': 0.009425117634236813}\n",
      "the sentiment is positive\n",
      "Куртка без дефектов, без запаха, доставка месяц. Материал тонкий , просвечивает наполнитель.  На ог 108 ,  от. 86 размер xxx сел отлично.\n",
      "{'positive': 0.9989412426948547, 'negative': 0.0010587110882624984}\n",
      "the sentiment is positive\n"
     ]
    }
   ],
   "source": [
    "# загружаем лучшую модель\n",
    "nlp = spacy.load(\"output/model-best\")\n",
    "texts = [\"Заказывала фиолетовую кофту размер XL, пришла очень маленькая кофта по длине 53 см и по груди тоже-детская разм. меньше чем S. Очень расстроилась, по спору присудили возврат денег 27 декабря. Выплата от 3 до 20 дней. Прошло уже 24 дня, деньги продавец не вернул, на сообщения не отвечает! Кофту такого смешного размера носить нельзя. Продавец непорядочный! Непонятно, почему Алиэкспресс после спора не отслеживают возвраты денег!\",\n",
    "         \"Ужасная синтетика! Тонкая, ничего общего с представленной картинкой, не яркая, рисунок растянут и тусклый, впрочем как и сама кофта- мешок! На картинке кажется приталенной на самом деле нет! Не рекомендую\",\n",
    "         \"Немного маловато,но жене понравилось\",\n",
    "         \"Куртка без дефектов, без запаха, доставка месяц. Материал тонкий , просвечивает наполнитель.  На ог 108 ,  от. 86 размер xxx сел отлично.\"]\n",
    "\n",
    "print(\"type : ‘quit’ to exit\")\n",
    "# predict the sentiment until someone writes quit\n",
    "for text in texts:\n",
    "    print(text)\n",
    "    doc = nlp(text)\n",
    "    print(doc.cats)\n",
    "    if doc.cats['positive'] > .5:\n",
    "        print(f\"the sentiment is positive\")\n",
    "    else:\n",
    "        print(f\"the sentiment is negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
